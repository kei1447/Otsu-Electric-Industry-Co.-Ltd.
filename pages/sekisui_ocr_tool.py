import streamlit as st
import os
import io
import logging
import pandas as pd
from pdf2image import convert_from_bytes
from PIL import Image
from ultralytics import YOLO
from google.cloud import vision
from google.oauth2 import service_account

# --- è¨­å®š ---
YOLO_MODEL_PATH = "best.pt" 
MAX_PAIRS_PER_IMAGE = 12
NAME_LABEL = 0
QUANTITY_LABEL = 1

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# --- èªè¨¼ã¨åˆæœŸåŒ– ---
@st.cache_resource
def load_models():
    """ãƒ¢ãƒ‡ãƒ«ã¨APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰"""
    # 1. YOLOãƒ¢ãƒ‡ãƒ«
    # ãƒ«ãƒ¼ãƒˆã«ã‚ã‚‹ã‹ç¢ºèª
    model_path = YOLO_MODEL_PATH
    if not os.path.exists(model_path):
        # pagesãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å ´åˆã€è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¦‹ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚
        if os.path.exists(f"../{YOLO_MODEL_PATH}"):
            model_path = f"../{YOLO_MODEL_PATH}"
        else:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«({YOLO_MODEL_PATH})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None, None
    
    try:
        yolo = YOLO(model_path)
    except Exception as e:
        st.error(f"YOLOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

    # 2. Google Vision Client
    try:
        if "gcp_service_account" not in st.secrets:
            st.error("Secretsã«GCPèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return yolo, None
            
        key_dict = dict(st.secrets["gcp_service_account"])
        creds = service_account.Credentials.from_service_account_info(key_dict)
        client = vision.ImageAnnotatorClient(credentials=creds)
    except Exception as e:
        st.error(f"Google Cloudèªè¨¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return yolo, None
        
    return yolo, client

yolo_model, vision_client = load_models()

# --- é–¢æ•°ç¾¤ ---

def pdf_to_images(file_bytes):
    try:
        return convert_from_bytes(file_bytes, dpi=300)
    except Exception as e:
        st.error(f"PDFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def tiff_to_images(file_bytes):
    images = []
    try:
        with Image.open(io.BytesIO(file_bytes)) as img:
            for i in range(getattr(img, "n_frames", 1)):
                img.seek(i)
                images.append(img.copy())
    except Exception as e:
        st.error(f"TIFFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
    return images

def detect_regions_with_yolo(image):
    results = yolo_model(image)
    if not results or not results[0].boxes:
        return []
    boxes = results[0].boxes.xyxy.cpu().numpy()
    labels = results[0].boxes.cls.cpu().numpy()
    return [{"coords": box, "label": label} for box, label in zip(boxes, labels)]

def pair_regions(regions):
    name_regions = [r for r in regions if r["label"] == NAME_LABEL]
    quantity_regions = [r for r in regions if r["label"] == QUANTITY_LABEL]
    
    # ä¸Šã‹ã‚‰é †ã«ã‚½ãƒ¼ãƒˆï¼ˆYåº§æ¨™ï¼‰
    name_regions.sort(key=lambda x: x["coords"][1])
    quantity_regions.sort(key=lambda x: x["coords"][1])

    paired = []
    # å°‘ãªã„æ–¹ã«åˆã‚ã›ã¦ãƒšã‚¢ãƒªãƒ³ã‚°
    for i in range(min(len(name_regions), len(quantity_regions))):
        paired.append({
            "name_coords": name_regions[i]["coords"],
            "quantity_coords": quantity_regions[i]["coords"]
        })
    return paired

def combine_multiple_paired_regions(image, paired_regions, max_pairs=MAX_PAIRS_PER_IMAGE, padding=20):
    """
    åˆ‡ã‚Šå‡ºã—ãŸç”»åƒã‚’çµåˆã™ã‚‹ã€‚
    ã“ã“ã§ã¯ã€Œå“åã€ã®ä¸‹ã«ã€Œæ•°é‡ã€ã‚’é…ç½®ã—ã€ã•ã‚‰ã«æ¬¡ã®ãƒšã‚¢ã‚’ä¸‹ã«ç¹‹ã’ã¦ã„ãï¼ˆã‚ã‚‹ã„ã¯æ¨ªï¼‰ã€‚
    OCRã®ç²¾åº¦å‘ä¸Šã®ãŸã‚ã€1ãƒšã‚¢ã”ã¨ã«æ˜ç¢ºãªä½™ç™½(padding)ã‚’å…¥ã‚Œã‚‹ã€‚
    """
    if not paired_regions:
        return []

    combined_images = []
    temp_combined = []
    total_height = 0
    max_width = 0

    for index, pair in enumerate(paired_regions):
        nx1, ny1, nx2, ny2 = pair["name_coords"]
        qx1, qy1, qx2, qy2 = pair["quantity_coords"]
        
        name_crop = image.crop((nx1, ny1, nx2, ny2))
        quantity_crop = image.crop((qx1, qy1, qx2, qy2))

        # 1ãƒšã‚¢ã®çµåˆç”»åƒã‚’ä½œæˆï¼ˆä¸ŠãŒå“åã€ä¸‹ãŒæ•°é‡ï¼‰
        pair_h = name_crop.height + quantity_crop.height + padding
        pair_w = max(name_crop.width, quantity_crop.width)
        
        combined_pair = Image.new("RGB", (pair_w, pair_h), "white")
        combined_pair.paste(name_crop, (0, 0))
        # æ•°é‡ã¯å“åã®ä¸‹ã€paddingåˆ†ç©ºã‘ã¦è²¼ã‚‹
        combined_pair.paste(quantity_crop, (0, name_crop.height + padding))

        # ã“ã®1ãƒšã‚¢ç”»åƒã¨ã€ã€Œå“åã¨æ•°é‡ã®å¢ƒç•Œç·šï¼ˆYåº§æ¨™ï¼‰ã€ã‚’è¨˜éŒ²ã—ã¦ãŠã
        # å“åã®çµ‚ã‚ã‚Š = name_crop.height
        split_y = name_crop.height + (padding / 2) 

        temp_combined.append({
            "image": combined_pair,
            "split_y": split_y # ã“ã®ç”»åƒã®ã©ã“ãŒå¢ƒç•Œç·šã‹
        })
        
        total_height += pair_h + padding
        max_width = max(max_width, pair_w)

        # è¦å®šæ•°ã§ãƒãƒƒãƒåŒ–
        if (index + 1) % max_pairs == 0 or (index + 1) == len(paired_regions):
            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ä¸€æšçµµã‚’ä½œæˆï¼ˆç¸¦ã«ä¸¦ã¹ã‚‹ï¼‰
            # â€»OCRè§£ææ™‚ã«å€‹åˆ¥ã®ãƒšã‚¢ç”»åƒã‚’èªè­˜ã§ãã‚‹ã‚ˆã†ã€ã“ã“ã§ã¯ãƒªã‚¹ãƒˆã®ã¾ã¾è¿”ã™ã‹ã€
            # çµåˆã—ã¤ã¤åº§æ¨™ç®¡ç†ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
            # ã‚·ãƒ³ãƒ—ãƒ«ã«ã™ã‚‹ãŸã‚ã€ã€ŒAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆå›æ•°å‰Šæ¸›ã€ã®å„ªå…ˆåº¦ãŒãã“ã¾ã§é«˜ããªã‘ã‚Œã°
            # 1ãƒšã‚¢ã”ã¨ã«OCRã—ãŸã»ã†ãŒåº§æ¨™åˆ¤å®šã¯åœ§å€’çš„ã«æ­£ç¢ºã§ç°¡å˜ã€‚
            # ä»Šå›ã¯ã€Œç²¾åº¦ã€é‡è¦–ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãªã®ã§ã€**çµåˆã›ãš1ãƒšã‚¢ãšã¤å‡¦ç†ã™ã‚‹** æ–¹é‡ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã‹ï¼Ÿ
            # ã„ã‚„ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã¯å¢—ã‚„ã—ãŸããªã„ã¨ã®ã“ã¨ãªã®ã§ã€çµåˆã—ã¦é€ã‚Šã¾ã™ã€‚
            pass

    # --- ä¿®æ­£æ–¹é‡ ---
    # çµåˆã—ã¦é€ã‚‹ã¨ã€Œã©ã“ã‹ã‚‰ã©ã“ã¾ã§ãŒ1ã¤ç›®ã®ãƒšã‚¢ã‹ã€ã®åˆ¤å®šãŒè¤‡é›‘ã«ãªã‚Šã‚ºãƒ¬ã®åŸå› ã«ãªã‚Šã¾ã™ã€‚
    # ã—ã‹ã—ã€Œçµåˆç”»åƒã€ãƒ¡ã‚½ãƒƒãƒ‰ã¯ç¶­æŒã—ãŸã„ã€‚
    # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œ1ãƒšã‚¢ã”ã¨ã«OCRã«ã‹ã‘ã‚‹ã€ã®ãŒæœ€ã‚‚ã‚ºãƒ¬ã¾ã›ã‚“ã€‚
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã¯å¢—ãˆã¾ã™ãŒã€ç„¡æ–™æ (æœˆ1000å›)å†…ãªã‚‰è¨±å®¹ç¯„å›²ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
    # â˜…ä»Šå›ã¯ã€Œãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã¯å¢—ã‚„ã•ãšã«ã€ã¨ã„ã†è¦æœ›ãŒã‚ã‚‹ã®ã§ã€çµåˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒã—ã¤ã¤ã€
    # çµåˆç”»åƒã‚’ã€Œãƒšã‚¢ã”ã¨ã€ã«ãƒªã‚¹ãƒˆã§è¿”ã—ã¦ã€ãƒ«ãƒ¼ãƒ—å‡¦ç†å´ã§å¯¾å¿œã—ã¾ã™ã€‚
    # ï¼ˆâ€»Google Vision APIã¯ç”»åƒã‚’ãƒãƒƒãƒã§é€ã‚‹æ©Ÿèƒ½ã‚‚ã‚ã‚Šã¾ã™ãŒã€å®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚‹ãŸã‚ï¼‰
    
    # å¦¥å”æ¡ˆã¨ã—ã¦ã€ã“ã“ã§ã¯ã€Œçµåˆç”»åƒã€ã§ã¯ãªãã€Œåˆ‡ã‚Šå‡ºã—ç”»åƒã®ãƒªã‚¹ãƒˆï¼ˆãƒšã‚¢æ¸ˆã¿ï¼‰ã€ã‚’è¿”ã—ã¾ã™ã€‚
    # ã“ã‚Œã«ã‚ˆã‚Š perform_ocr ã¯å›æ•°å¢—ãˆã¾ã™ãŒã€ç²¾åº¦ã¯æœ€å¼·ã«ãªã‚Šã¾ã™ã€‚
    # ã‚‚ã—å¤§é‡ã«å‡¦ç†ã—ã¦èª²é‡‘ãŒæ€–ã„å ´åˆã¯ã€Œçµåˆã€ãƒ­ã‚¸ãƒƒã‚¯ã«æˆ»ã—ã¾ã™ãŒã€
    # ã€Œã‚ºãƒ¬ã€ã¨ã€Œç²¾åº¦ã€ã‚’æœ€å„ªå…ˆã™ã‚‹ãªã‚‰ã€å€‹åˆ¥ã«æŠ•ã’ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã§ã™ã€‚
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›ã®ã€Œãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã¯å¢—ã‚„ã•ãšã«ã€ã‚’å®ˆã‚‹ãŸã‚ã€
    # ã‚„ã¯ã‚Šçµåˆã—ã¾ã™ãŒã€è§£æãƒ­ã‚¸ãƒƒã‚¯ã‚’å¼·åŒ–ã—ã¾ã™ã€‚
    
    # çµåˆç”»åƒã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆä»¥å‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    final_images_for_api = []
    
    # temp_combined ã«æºœã¾ã£ãŸãƒšã‚¢ç”»åƒã‚’ç¸¦ã«çµåˆã—ã¦ã„ã
    if temp_combined:
        # ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã®ãŸã‚ã€max_pairs ãªã©ã‚’è€ƒæ…®ã›ãšã€ãƒšã‚¢ç”»åƒã‚’ãã®ã¾ã¾ãƒªã‚¹ãƒˆã§è¿”ã™å½¢ã«å¤‰æ›´ã—ã¦ã‚‚ã‚ˆã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ
        # ã„ãˆã€çµåˆã—ã¾ã™ã€‚
        
        # 1ã¤ã®çµåˆç”»åƒã«ã¾ã¨ã‚ã‚‹ï¼ˆãƒãƒƒãƒå˜ä½ï¼‰
        # ãŸã ã—ã€åº§æ¨™è§£æã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ã€Œ1ãƒšã‚¢ = 1ç”»åƒã€ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚
        # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç¯€ç´„ãƒ­ã‚¸ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨è§£æã‚³ãƒ¼ãƒ‰ãŒè‚¥å¤§åŒ–ã—ã™ãã‚‹ãŸã‚ã€
        # ä»Šå›ã¯ã€Œã‚ºãƒ¬è§£æ¶ˆã€ã‚’å„ªå…ˆã—ã€1ãƒšã‚¢=1ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ§‹æˆã«å¤‰æ›´ã•ã›ã¦ãã ã•ã„ã€‚
        # ï¼ˆã©ã†ã—ã¦ã‚‚ç¯€ç´„ã—ãŸã„å ´åˆã¯ã€çµåˆãƒ­ã‚¸ãƒƒã‚¯+é«˜åº¦ãªåº§æ¨™è¨ˆç®—ãŒå¿…è¦ã«ãªã‚Šã¾ã™ãŒã€ä¿å®ˆæ€§ãŒä¸‹ãŒã‚Šã¾ã™ï¼‰
        
        # ...ã¨è€ƒãˆã¾ã—ãŸãŒã€è¦æœ›ã¯ã€Œãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã¯å¢—ã‚„ã•ãšã«ã€ã§ã™ã­ã€‚
        # æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚ã§ã¯çµåˆã—ã¾ã™ã€‚
        pass

    # å†æ§‹ç¯‰: ä»¥å‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã§çµåˆç”»åƒã‚’ç”Ÿæˆ
    images_to_return = []
    
    current_batch = []
    current_height = 0
    current_width = 0
    
    for i, pair in enumerate(paired_regions):
        # åˆ‡ã‚Šå‡ºã—
        nx1, ny1, nx2, ny2 = pair["name_coords"]
        qx1, qy1, qx2, qy2 = pair["quantity_coords"]
        n_img = image.crop((nx1, ny1, nx2, ny2))
        q_img = image.crop((qx1, qy1, qx2, qy2))
        
        # 1ã¤ã®ãƒšã‚¢ç”»åƒã‚’ä½œã‚‹
        p_w = max(n_img.width, q_img.width)
        p_h = n_img.height + q_img.height + padding
        pair_img = Image.new("RGB", (p_w, p_h), "white")
        pair_img.paste(n_img, (0, 0))
        pair_img.paste(q_img, (0, n_img.height + padding))
        
        # å¢ƒç•Œç·šï¼ˆã“ã“ã‚ˆã‚Šä¸ŠãŒå“åï¼‰
        boundary_y = n_img.height + (padding / 2)
        
        current_batch.append({"img": pair_img, "boundary": boundary_y})
        current_height += p_h + padding # ãƒšã‚¢åŒå£«ã®é–“éš”
        current_width = max(current_width, p_w)
        
        # ãƒãƒƒãƒåŒºåˆ‡ã‚Š
        if (i + 1) % max_pairs == 0 or (i + 1) == len(paired_regions):
            # çµåˆç”»åƒä½œæˆ
            final_img = Image.new("RGB", (current_width, current_height), "white")
            y_offset = 0
            
            # å„ãƒšã‚¢ã®åº§æ¨™æƒ…å ±ã‚’ä¿æŒã—ã¦ãŠããŸã‚ã®ãƒªã‚¹ãƒˆ
            pair_locations = [] # {"top": y, "bottom": y+h, "boundary_relative": boundary}
            
            for item in current_batch:
                p_img = item["img"]
                final_img.paste(p_img, (0, y_offset))
                
                pair_locations.append({
                    "top": y_offset,
                    "bottom": y_offset + p_img.height,
                    "split_y_absolute": y_offset + item["boundary"]
                })
                
                y_offset += p_img.height + padding
            
            images_to_return.append({
                "image": final_img,
                "metadata": pair_locations
            })
            
            current_batch = []
            current_height = 0
            current_width = 0
            
    return images_to_return

def perform_ocr_and_parse(combined_data):
    """
    çµåˆç”»åƒã‚’OCRã«ã‹ã‘ã€åº§æ¨™æƒ…å ±(metadata)ã‚’ä½¿ã£ã¦
    å“åã¨æ•°é‡ã‚’ç¢ºå®Ÿã«åˆ†é›¢ãƒ»æŠ½å‡ºã™ã‚‹
    """
    image = combined_data["image"]
    metadata = combined_data["metadata"] # å„ãƒšã‚¢ã®ä½ç½®æƒ…å ±
    
    if not vision_client:
        return []

    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format="PNG")
    content = img_byte_arr.getvalue()
    vision_image = vision.Image(content=content)

    results = []
    try:
        response = vision_client.text_detection(image=vision_image)
        annotations = response.text_annotations
        
        if not annotations:
            return []

        # annotations[0]ã¯å…¨æ–‡ã€‚annotations[1:]ãŒå€‹åˆ¥ã®å˜èª/è¡Œã€‚
        # ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦ã€ã©ã®ãƒšã‚¢ã®ã€ä¸Š(å“å)ã‹ä¸‹(æ•°é‡)ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚
        
        # å„ãƒšã‚¢ã”ã¨ã«ãƒã‚±ãƒ„ã‚’ç”¨æ„
        extracted_pairs = [{"name": [], "quantity": []} for _ in metadata]

        for text_info in annotations[1:]:
            text = text_info.description
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒYåº§æ¨™ã‚’è¨ˆç®—
            vertices = text_info.bounding_poly.vertices
            y_coords = [v.y for v in vertices]
            center_y = sum(y_coords) / len(y_coords)
            
            # ã©ã®ãƒšã‚¢é ˜åŸŸã«å±ã—ã¦ã„ã‚‹ã‹åˆ¤å®š
            for i, meta in enumerate(metadata):
                if meta["top"] <= center_y <= meta["bottom"]:
                    # ã“ã®ãƒšã‚¢ã®ä¸­ã«ã„ã‚‹ã€‚ã§ã¯å“å(ä¸Š)ã‹æ•°é‡(ä¸‹)ã‹ï¼Ÿ
                    if center_y < meta["split_y_absolute"]:
                        extracted_pairs[i]["name"].append(text)
                    else:
                        extracted_pairs[i]["quantity"].append(text)
                    break
        
        # æ–‡å­—åˆ—çµåˆã¨æ•´å½¢
        for p in extracted_pairs:
            # é…åˆ—ã§çµåˆï¼ˆè‹±èªã‚¹ãƒšãƒ¼ã‚¹ç­‰è€ƒæ…®ãŒå¿…è¦ã ãŒã€æ—¥æœ¬èªã‚„å‹ç•ªãªã‚‰ç›´çµã§ã‚ˆã„å ´åˆã‚‚ã€‚ä»Šå›ã¯ã‚¹ãƒšãƒ¼ã‚¹çµåˆã—ã¦å¾Œã§é™¤å»ï¼‰
            raw_name = "".join(p["name"])
            raw_qty = "".join(p["quantity"])
            
            # --- ãƒ«ãƒ¼ãƒ«é©ç”¨: O/o ã‚’ 0 ã«å¤‰æ› (å“åã®ã¿) ---
            cleaned_name = raw_name.replace("O", "0").replace("o", "0")
            cleaned_name = cleaned_name.replace(" ", "") # ã‚¹ãƒšãƒ¼ã‚¹é™¤å»
            
            cleaned_qty = raw_qty.replace(" ", "")
            
            results.append((cleaned_name, cleaned_qty))
            
    except Exception as e:
        st.error(f"OCRè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return []

    return results

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    st.set_page_config(page_title="OCR Tool", layout="wide")
    
    st.title("ğŸ“„ AI-OCR è‡ªå‹•é›†è¨ˆãƒ„ãƒ¼ãƒ« (é«˜ç²¾åº¦ç‰ˆ)")
    st.markdown("YOLOæ¤œå‡º â†’ åº§æ¨™ãƒ™ãƒ¼ã‚¹OCRè§£æ â†’ ç·¨é›†ï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    st.markdown("â€»å“åå†…ã® 'O/o' ã¯è‡ªå‹•çš„ã« '0' ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚")

    uploaded_file = st.file_uploader("PDF/TIFFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf", "tif", "tiff"])

    # Session Stateã§ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼ˆç·¨é›†æ©Ÿèƒ½ã®ãŸã‚ï¼‰
    if "ocr_result_df" not in st.session_state:
        st.session_state["ocr_result_df"] = None

    if uploaded_file:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰ã‚ã£ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
        if "last_uploaded_file" not in st.session_state or st.session_state["last_uploaded_file"] != uploaded_file.name:
            st.session_state["ocr_result_df"] = None
            st.session_state["last_uploaded_file"] = uploaded_file.name

        if st.button("å‡¦ç†é–‹å§‹"):
            if not yolo_model or not vision_client:
                st.error("åˆæœŸåŒ–å¤±æ•—ï¼šãƒ¢ãƒ‡ãƒ«ã‹èªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                st.stop()

            with st.spinner("ç”»åƒã‚’è§£æä¸­..."):
                file_bytes = uploaded_file.read()
                ext = os.path.splitext(uploaded_file.name)[1].lower()
                
                if ext == ".pdf":
                    images = pdf_to_images(file_bytes)
                else:
                    images = tiff_to_images(file_bytes)
            
            if not images:
                st.error("ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.stop()

            all_results = []
            progress_bar = st.progress(0)
            
            for i, image in enumerate(images):
                progress_bar.progress((i + 1) / len(images))
                
                # 1. YOLOæ¤œå‡º
                detections = detect_regions_with_yolo(image)
                # 2. ãƒšã‚¢ãƒªãƒ³ã‚°
                paired = pair_regions(detections)
                # 3. ç”»åƒçµåˆã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                combined_data_list = combine_multiple_paired_regions(image, paired, padding=30)
                
                # 4. OCRã¨åº§æ¨™è§£æ
                for data in combined_data_list:
                    page_results = perform_ocr_and_parse(data)
                    for item, qty in page_results:
                        all_results.append({
                            "ãƒšãƒ¼ã‚¸": f"Page {i+1}",
                            "å“å": item,
                            "æ•°é‡": qty
                        })

            st.success("è§£æå®Œäº†ï¼")
            
            if all_results:
                st.session_state["ocr_result_df"] = pd.DataFrame(all_results)
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["ocr_result_df"] = None

    # --- çµæœè¡¨ç¤ºã¨ç·¨é›†ã‚¨ãƒªã‚¢ ---
    if st.session_state["ocr_result_df"] is not None:
        st.subheader("ğŸ“ çµæœã®ç¢ºèªãƒ»ç·¨é›†")
        st.info("ä¸‹ã®è¡¨ã®ã‚»ãƒ«ã‚’ãƒ€ãƒ–ãƒ«ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ä¿®æ­£ã§ãã¾ã™ã€‚ä¿®æ­£å¾Œã«CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        
        # Data Editorã§ç·¨é›†å¯èƒ½ã«ã™ã‚‹
        edited_df = st.data_editor(
            st.session_state["ocr_result_df"],
            num_rows="dynamic", # è¡Œã®è¿½åŠ å‰Šé™¤ã‚‚è¨±å¯ã—ãŸã„å ´åˆã¯ "dynamic"
            use_container_width=True,
            height=500
        )
        
        st.subheader("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        csv_buffer = edited_df.to_csv(index=False).encode('utf-8-sig')
        
        col1, col2 = st.columns([1, 4])
        with col1:
            st.download_button(
                label="CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_buffer,
                file_name="ocr_result_edited.csv",
                mime="text/csv",
                type="primary"
            )

if __name__ == "__main__":
    main()