import streamlit as st
import os
import io
import logging
import pandas as pd
from pdf2image import convert_from_bytes
from PIL import Image
from ultralytics import YOLO
from google.cloud import vision
from google.oauth2 import service_account

# --- ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼ãƒã‚§ãƒƒã‚¯ ---
if "password_correct" not in st.session_state or not st.session_state["password_correct"]:
    st.warning("âš ï¸ ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã¾ã›ã‚“ã€‚å·¦ä¸Šã®ã€Œappã€ã«æˆ»ã£ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- è¨­å®š ---
YOLO_MODEL_PATH = "best.pt" 
MAX_PAIRS_PER_IMAGE = 12
NAME_LABEL = 0
QUANTITY_LABEL = 1

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# --- èªè¨¼ã¨åˆæœŸåŒ– ---
@st.cache_resource
def load_models():
    """ãƒ¢ãƒ‡ãƒ«ã¨APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰"""
    # 1. YOLOãƒ¢ãƒ‡ãƒ«
    model_path = YOLO_MODEL_PATH
    if not os.path.exists(model_path):
        if os.path.exists(f"../{YOLO_MODEL_PATH}"):
            model_path = f"../{YOLO_MODEL_PATH}"
        else:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«({YOLO_MODEL_PATH})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None, None
    
    try:
        yolo = YOLO(model_path)
    except Exception as e:
        st.error(f"YOLOãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

    # 2. Google Vision Client
    try:
        if "gcp_service_account" not in st.secrets:
            st.error("Secretsã«GCPèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return yolo, None
            
        key_dict = dict(st.secrets["gcp_service_account"])
        creds = service_account.Credentials.from_service_account_info(key_dict)
        client = vision.ImageAnnotatorClient(credentials=creds)
    except Exception as e:
        st.error(f"Google Cloudèªè¨¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return yolo, None
        
    return yolo, client

yolo_model, vision_client = load_models()

# --- é–¢æ•°ç¾¤ ---

def pdf_to_images(file_bytes):
    try:
        return convert_from_bytes(file_bytes, dpi=300)
    except Exception as e:
        st.error(f"PDFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def tiff_to_images(file_bytes):
    images = []
    try:
        with Image.open(io.BytesIO(file_bytes)) as img:
            for i in range(getattr(img, "n_frames", 1)):
                img.seek(i)
                images.append(img.copy())
    except Exception as e:
        st.error(f"TIFFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
    return images

def detect_regions_with_yolo(image):
    results = yolo_model(image)
    if not results or not results[0].boxes:
        return []
    boxes = results[0].boxes.xyxy.cpu().numpy()
    labels = results[0].boxes.cls.cpu().numpy()
    return [{"coords": box, "label": label} for box, label in zip(boxes, labels)]

def pair_regions(regions):
    name_regions = [r for r in regions if r["label"] == NAME_LABEL]
    quantity_regions = [r for r in regions if r["label"] == QUANTITY_LABEL]
    
    # ä¸Šã‹ã‚‰é †ã«ã‚½ãƒ¼ãƒˆï¼ˆYåº§æ¨™ï¼‰
    name_regions.sort(key=lambda x: x["coords"][1])
    quantity_regions.sort(key=lambda x: x["coords"][1])

    paired = []
    # å°‘ãªã„æ–¹ã«åˆã‚ã›ã¦ãƒšã‚¢ãƒªãƒ³ã‚°
    for i in range(min(len(name_regions), len(quantity_regions))):
        paired.append({
            "name_coords": name_regions[i]["coords"],
            "quantity_coords": quantity_regions[i]["coords"]
        })
    return paired

def combine_multiple_paired_regions(image, paired_regions, max_pairs=MAX_PAIRS_PER_IMAGE, padding=20):
    if not paired_regions:
        return []

    images_to_return = []
    
    current_batch = []
    current_height = 0
    current_width = 0
    
    for i, pair in enumerate(paired_regions):
        nx1, ny1, nx2, ny2 = pair["name_coords"]
        qx1, qy1, qx2, qy2 = pair["quantity_coords"]
        n_img = image.crop((nx1, ny1, nx2, ny2))
        q_img = image.crop((qx1, qy1, qx2, qy2))
        
        p_w = max(n_img.width, q_img.width)
        p_h = n_img.height + q_img.height + padding
        pair_img = Image.new("RGB", (p_w, p_h), "white")
        pair_img.paste(n_img, (0, 0))
        pair_img.paste(q_img, (0, n_img.height + padding))
        
        boundary_y = n_img.height + (padding / 2)
        
        current_batch.append({"img": pair_img, "boundary": boundary_y})
        current_height += p_h + padding
        current_width = max(current_width, p_w)
        
        if (i + 1) % max_pairs == 0 or (i + 1) == len(paired_regions):
            final_img = Image.new("RGB", (current_width, current_height), "white")
            y_offset = 0
            
            pair_locations = []
            
            for item in current_batch:
                p_img = item["img"]
                final_img.paste(p_img, (0, y_offset))
                
                pair_locations.append({
                    "top": y_offset,
                    "bottom": y_offset + p_img.height,
                    "split_y_absolute": y_offset + item["boundary"]
                })
                
                y_offset += p_img.height + padding
            
            images_to_return.append({
                "image": final_img,
                "metadata": pair_locations
            })
            
            current_batch = []
            current_height = 0
            current_width = 0
            
    return images_to_return

def perform_ocr_and_parse(combined_data):
    image = combined_data["image"]
    metadata = combined_data["metadata"]
    
    if not vision_client:
        return []

    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format="PNG")
    content = img_byte_arr.getvalue()
    vision_image = vision.Image(content=content)

    results = []
    try:
        response = vision_client.text_detection(image=vision_image)
        annotations = response.text_annotations
        
        if not annotations:
            return []

        extracted_pairs = [{"name": [], "quantity": []} for _ in metadata]

        for text_info in annotations[1:]:
            text = text_info.description
            vertices = text_info.bounding_poly.vertices
            y_coords = [v.y for v in vertices]
            center_y = sum(y_coords) / len(y_coords)
            
            for i, meta in enumerate(metadata):
                if meta["top"] <= center_y <= meta["bottom"]:
                    if center_y < meta["split_y_absolute"]:
                        extracted_pairs[i]["name"].append(text)
                    else:
                        extracted_pairs[i]["quantity"].append(text)
                    break
        
        for p in extracted_pairs:
            raw_name = "".join(p["name"])
            raw_qty = "".join(p["quantity"])
            
            # O/o -> 0 å¤‰æ›
            cleaned_name = raw_name.replace("O", "0").replace("o", "0")
            cleaned_name = cleaned_name.replace(" ", "")
            
            cleaned_qty = raw_qty.replace(" ", "")
            
            results.append((cleaned_name, cleaned_qty))
            
    except Exception as e:
        st.error(f"OCRè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return []

    return results

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    st.set_page_config(page_title="OCR Tool", layout="wide")
    
    st.title("ğŸ“„ AI-OCR è‡ªå‹•é›†è¨ˆãƒ„ãƒ¼ãƒ«")
    st.markdown("YOLOæ¤œå‡º â†’ åº§æ¨™ãƒ™ãƒ¼ã‚¹OCRè§£æ â†’ ç·¨é›†ï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

    uploaded_file = st.file_uploader("PDF/TIFFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ä¾‹: 251223AM.pdf)", type=["pdf", "tif", "tiff"])

    if "ocr_result_df" not in st.session_state:
        st.session_state["ocr_result_df"] = None

    if uploaded_file:
        if "last_uploaded_file" not in st.session_state or st.session_state["last_uploaded_file"] != uploaded_file.name:
            st.session_state["ocr_result_df"] = None
            st.session_state["last_uploaded_file"] = uploaded_file.name

        if st.button("å‡¦ç†é–‹å§‹"):
            if not yolo_model or not vision_client:
                st.error("åˆæœŸåŒ–å¤±æ•—ï¼šãƒ¢ãƒ‡ãƒ«ã‹èªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                st.stop()

            with st.spinner("ç”»åƒã‚’è§£æä¸­..."):
                file_bytes = uploaded_file.read()
                ext = os.path.splitext(uploaded_file.name)[1].lower()
                
                if ext == ".pdf":
                    images = pdf_to_images(file_bytes)
                else:
                    images = tiff_to_images(file_bytes)
            
            if not images:
                st.error("ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.stop()

            all_results = []
            progress_bar = st.progress(0)
            
            for i, image in enumerate(images):
                progress_bar.progress((i + 1) / len(images))
                
                detections = detect_regions_with_yolo(image)
                paired = pair_regions(detections)
                combined_data_list = combine_multiple_paired_regions(image, paired, padding=30)
                
                for data in combined_data_list:
                    page_results = perform_ocr_and_parse(data)
                    for item, qty in page_results:
                        all_results.append({
                            "ãƒšãƒ¼ã‚¸": f"Page {i+1}",
                            "å“å": item,
                            "æ•°é‡": qty
                        })

            st.success("è§£æå®Œäº†ï¼")
            
            if all_results:
                st.session_state["ocr_result_df"] = pd.DataFrame(all_results)
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.session_state["ocr_result_df"] = None

    # --- çµæœè¡¨ç¤ºã¨ç·¨é›†ã‚¨ãƒªã‚¢ ---
    if st.session_state["ocr_result_df"] is not None:
        st.subheader("ğŸ“ çµæœã®ç¢ºèªãƒ»ç·¨é›†")
        st.info("ä¸‹ã®è¡¨ã‚’ç·¨é›†å¾Œã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        
        edited_df = st.data_editor(
            st.session_state["ocr_result_df"],
            num_rows="dynamic",
            use_container_width=True,
            height=500
        )
        
        st.subheader("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        # â–¼â–¼â–¼ ãƒ•ã‚¡ã‚¤ãƒ«åè‡ªå‹•ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ â–¼â–¼â–¼
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾— (ä¾‹: 251223AM.pdf)
        original_name = st.session_state.get("last_uploaded_file", "result.csv")
        # æ‹¡å¼µå­ã‚’é™¤å» (ä¾‹: 251223AM)
        base_name = os.path.splitext(original_name)[0]
        # é ­ã« '20' ã‚’ã¤ã‘ã¦ .csv ã«ã™ã‚‹ (ä¾‹: 20251223AM.csv)
        download_filename = f"20{base_name}.csv"
        # â–²â–²â–² ã“ã“ã¾ã§ â–²â–²â–²
        
        csv_buffer = edited_df.to_csv(index=False).encode('utf-8-sig')
        
        col1, col2 = st.columns([1, 4])
        with col1:
            st.download_button(
                label=f"CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({download_filename})", # ãƒœã‚¿ãƒ³ã«ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¡¨ç¤º
                data=csv_buffer,
                file_name=download_filename,
                mime="text/csv",
                type="primary"
            )

if __name__ == "__main__":
    main()